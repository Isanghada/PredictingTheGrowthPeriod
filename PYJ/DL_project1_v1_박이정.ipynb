{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "\bDL_project1_v1_박이정.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyPQpj+qXm5iTt8WQckfaw0R",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/happyfranc/ml_project/blob/main/%08DL_project1_v1_%EB%B0%95%EC%9D%B4%EC%A0%95.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "생육 기간 예측 프로젝트\n",
        "\n",
        "목적 및 배경 : 한 쌍의 이미지를 입력받아 작물의 생육 기간을 예측하는 모델 개발\n",
        "\n",
        "데이터 정보 및 학습 진행 방식 : DACON \"생육 기간 예측 경진대회\" 데이터\n",
        "\n",
        "2개 작물(청경채, 적상추)에 대한 생육 기간 경과일자별 이미지 데이터 저장\n",
        "- 학습 : 753개(청경채 353개, 적상추 400개)\n",
        "- 테스트 : 307개(청경채 139개, 적상추 168개)\n",
        "\n",
        "\n",
        "작물별 이미지 2장씩을 다양하게 조합하여 2장의 이미지간 경과일을 기준으로 학습 및 평가 진행 예정\n",
        "\n",
        "모델 평가 기준 : RMSE(Root Mean Squared Error)"
      ],
      "metadata": {
        "id": "Mgcu5w7135g5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "_mnxyFv9HteI"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "from glob import glob\n",
        "import os\n",
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torch import optim\n",
        "from torch import nn\n",
        "from torchvision.transforms import ToTensor\n",
        "from torchvision import transforms\n",
        "from tqdm.auto import tqdm"
      ],
      "metadata": {
        "id": "NX6D2-7kG0eR"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "p7oLel0vHv8x",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "559c8206-2423-4c16-cbb6-f532821b29e8"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# seed 고정\n",
        "def seed_everything(seed):\n",
        "    # 파이토치 및 넘파이, random 등 관련 모듈에 대한 seed 일괄 설정\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)  # multi-GPU\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "    np.random.seed(seed)\n",
        "    random.seed(seed)\n",
        "\n",
        "seed_everything(2048)"
      ],
      "metadata": {
        "id": "6A8ouGFZHv_4"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "is_cuda = torch.cuda.is_available()\n",
        "device = torch.device('cuda' if is_cuda else 'cpu')\n",
        "\n",
        "lr = 0.00005\n",
        "epochs = 10\n",
        "batch_size = 64\n",
        "valid_batch_size = 50 ## 확인"
      ],
      "metadata": {
        "id": "dSXDdpsoHwCe"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 파일 path\n",
        "train_path = '/content/drive/MyDrive/ds_study/data/train_dataset'\n",
        "test_path = '/content/drive/MyDrive/ds_study/data/test_dataset'"
      ],
      "metadata": {
        "id": "_2nCRwJ0HwEz"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data resize 저장 함수\n",
        "def data_resize(species_nm,root_path):\n",
        "  os.mkdir(root_path +'/'+ species_nm + '_resize')\n",
        "  for sub_path in os.listdir(root_path +'/'+ species_nm): # 서브 폴더 생성\n",
        "    os.mkdir(root_path +'/'+ species_nm + '_resize/' + sub_path)\n",
        "    for image_path in glob(root_path +'/'+ species_nm + '/' + sub_path + '/*'): # 이미지 resize 및 저장\n",
        "      image_file_name = image_path.split('/')[-1]\n",
        "      img = Image.open(image_path)\n",
        "      img = img.resize((224, 224))\n",
        "      img.save(root_path +'/'+ species_nm + '_resize/' + sub_path + '/' + image_file_name)"
      ],
      "metadata": {
        "id": "y3xNKo_xwzG5"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# BC train\n",
        "#data_resize('BC',train_path)"
      ],
      "metadata": {
        "id": "foQikkVfxAiJ"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# LT train\n",
        "#data_resize('LT',train_path)"
      ],
      "metadata": {
        "id": "y9kr7cD4xAkw"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# BC test\n",
        "#data_resize('BC',test_path)"
      ],
      "metadata": {
        "id": "SS8LO-VxxAnG"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# LT test\n",
        "#data_resize('LT',test_path)"
      ],
      "metadata": {
        "id": "RUNnFaXBxAo7"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(glob(train_path + '/BC/**/**')),len(glob(train_path + '/BC_resize/**/**')))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mH6NEvT3d-RD",
        "outputId": "4910c046-6443-40c0-9415-2ab2c3e3f50c"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "353 353\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(glob(train_path + '/LT/**/**')),len(glob(train_path + '/LT_resize/**/**')))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4A-vtL5Vd-Ta",
        "outputId": "993045c5-c140-4719-afe5-8e3190b2c2e0"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "400 400\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 파일 이름에서 날짜 추출\n",
        "def extract_day(file_name):\n",
        "  day = int(file_name.split('.')[-2][-2:])\n",
        "  return day"
      ],
      "metadata": {
        "id": "jSvH9lziHwHb"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 파일 이름에서 날짜 추출 후 array 파일로 만들기\n",
        "def make_day_array(file_name):\n",
        "  day_array = np.array([extract_day(file_name) for file_name in file_name])\n",
        "  return day_array"
      ],
      "metadata": {
        "id": "jLFZcUwQankL"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# image path array 생성\n",
        "def make_image_path_array(root_path):\n",
        "  bc_directories = glob(root_path + '/BC_resize/*')\n",
        "  lt_directories = glob(root_path + '/LT_resize/*')\n",
        "  \n",
        "  # bc 이미지 확인\n",
        "  bc_image_path = []  \n",
        "  for bc_path in bc_directories:\n",
        "    images = glob(bc_path + '/*.png')\n",
        "    bc_image_path.extend(images)\n",
        "    print(len(bc_image_path))\n",
        "\n",
        "  # lt 이미지 확인\n",
        "  lt_image_path = []  \n",
        "  for lt_path in lt_directories:\n",
        "    images = glob(lt_path + '/*.png')\n",
        "    lt_image_path.extend(images)\n",
        "    print(len(lt_image_path))\n",
        "    \n",
        "  return bc_image_path, lt_image_path"
      ],
      "metadata": {
        "id": "HFtRt2-FMuRC"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# DataFrame 만들기(columns = 파일 이름, 일자, 종)\n",
        "def make_dataframe(root_path):\n",
        "  bc_image_path, lt_image_path = make_image_path_array(root_path) # 데이터 저장 경로 입력 후 파일 리스트 생성\n",
        "  bc_day_array = make_day_array(bc_image_path) # bc 파일 이름에서 날짜 추출 후 array 만들기\n",
        "  lt_day_array = make_day_array(lt_image_path) # lt 파일 이름에서 날짜 추출 후 array 만들기\n",
        "\n",
        "  bc_df = pd.DataFrame({\"file_name\": bc_image_path, \n",
        "                        \"day\" : bc_day_array})\n",
        "\n",
        "  bc_df['species'] = 'bc' # 종 추가\n",
        "\n",
        "\n",
        "  lt_df = pd.DataFrame({\"file_name\": lt_image_path,\n",
        "                        \"day\" : lt_day_array})\n",
        "\n",
        "  lt_df['species'] = 'lt' # 종 추가\n",
        "\n",
        "  total_data_frame = pd.concat([bc_df, lt_df]).reset_index(drop=True)\n",
        "\n",
        "  return total_data_frame"
      ],
      "metadata": {
        "id": "mHsltK2YMuUI"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#length만큼 2개씩 sampling한 결과 dataframe 만들기\n",
        "def make_combination(length, species, data_frame, direct_name):\n",
        "    before_file_path = []\n",
        "    after_file_path = []\n",
        "    time_delta = []\n",
        "\n",
        "    for i in range(length):\n",
        "      # 하위 폴더 중 랜덤하게 선택\n",
        "      direct = random.randrange(0,len(direct_name))\n",
        "      # 위에서 결정된 폴더를 선택\n",
        "      temp = data_frame[data_frame['version'] == direct_name[direct]]\n",
        "\n",
        "      # sample 이용해서 dataframe에서 2개 뽑기\n",
        "      sample = temp[temp['species'] == species].sample(2)\n",
        "      # day가 더 큰 sample을 after\n",
        "      after = sample[sample['day'] == max(sample['day'])].reset_index(drop=True)\n",
        "      # day가 더 작은 sample을 before\n",
        "      before = sample[sample['day'] == min(sample['day'])].reset_index(drop=True)\n",
        "\n",
        "      before_file_path.append(before.iloc[0]['file_name'])\n",
        "      after_file_path.append(after.iloc[0]['file_name'])\n",
        "      delta = int(after.iloc[0]['day'] - before.iloc[0]['day'])\n",
        "      time_delta.append(delta)\n",
        "\n",
        "    combination_df = pd.DataFrame({\n",
        "        'before_file_path': before_file_path,\n",
        "        'after_file_path': after_file_path,\n",
        "        'time_delta': time_delta,\n",
        "    })\n",
        "\n",
        "    combination_df['species'] = species\n",
        "\n",
        "    return combination_df"
      ],
      "metadata": {
        "id": "nrqtvt9uZGxE"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# BC 폴더와 LT 폴더에 있는 하위 폴더를 저장한다.\n",
        "bc_direct = glob(train_path + '/BC_resize/*')\n",
        "bc_direct_name = [x[-5:] for x in bc_direct]\n",
        "print(bc_direct_name)\n",
        "lt_direct = glob(train_path + '/LT_resize/*')\n",
        "lt_direct_name = [x[-5:] for x in lt_direct]\n",
        "print(lt_direct_name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TD7JFmbDbrZn",
        "outputId": "e7409e1f-5cae-4fdf-d538-06ba4e584e48"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['BC_09', 'BC_06', 'BC_07', 'BC_01', 'BC_02', 'BC_08', 'BC_04', 'BC_05', 'BC_03']\n",
            "['LT_05', 'LT_03', 'LT_02', 'LT_04', 'LT_00', 'LT_07', 'LT_09', 'LT_08', 'LT_01', 'LT_06']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 하위 폴더에 있는 이미지들을 하위 폴더 이름과 매칭시켜서 저장한다.\n",
        "bc_images = {key : glob(name + '/*.png') for key,name in zip(bc_direct_name, bc_direct)}\n",
        "lt_images = {key : glob(name + '/*.png') for key,name in zip(lt_direct_name, lt_direct)}"
      ],
      "metadata": {
        "id": "RbkDORLOo06e"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 하위 폴더에 있는 이미지들에서 날짜 정보만 따로 저장한다.\n",
        "bc_dayes = {key : make_day_array(bc_images[key]) for key in bc_direct_name}\n",
        "lt_dayes = {key : make_day_array(lt_images[key]) for key in lt_direct_name}"
      ],
      "metadata": {
        "id": "btGupB0upP_4"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bc_dfs = []\n",
        "for i in bc_direct_name:\n",
        "    bc_df = pd.DataFrame({\n",
        "        'file_name':bc_images[i],\n",
        "        'day':bc_dayes[i],\n",
        "        'species':'bc',\n",
        "        'version':i\n",
        "    })\n",
        "    bc_dfs.append(bc_df)\n",
        "    \n",
        "lt_dfs = []\n",
        "for i in lt_direct_name:\n",
        "    lt_df = pd.DataFrame({\n",
        "        'file_name':lt_images[i],\n",
        "        'day':lt_dayes[i],\n",
        "        'species':'lt',\n",
        "        'version':i\n",
        "    })\n",
        "    lt_dfs.append(lt_df)"
      ],
      "metadata": {
        "id": "qTjwxQSUo09E"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터셋 만들기\n",
        "# 1000개, 8 : 2\n",
        "bc_dataframe = pd.concat(bc_dfs).reset_index(drop=True)\n",
        "lt_dataframe = pd.concat(lt_dfs).reset_index(drop=True)\n",
        "total_dataframe = pd.concat([bc_dataframe, lt_dataframe]).reset_index(drop=True)\n",
        "\n",
        "\n",
        "bc_combination = make_combination(1000, 'bc', total_dataframe, bc_direct_name)\n",
        "lt_combination = make_combination(1000, 'lt', total_dataframe, lt_direct_name)\n",
        "\n",
        "bc_train = bc_combination.iloc[:800]\n",
        "bc_valid = bc_combination.iloc[800:]\n",
        "\n",
        "lt_train = lt_combination.iloc[:800]\n",
        "lt_valid = lt_combination.iloc[800:]\n",
        "\n",
        "train_set = pd.concat([bc_train, lt_train])\n",
        "valid_set = pd.concat([bc_valid, lt_valid])"
      ],
      "metadata": {
        "id": "eiqn4ccvMuf6"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#length만큼 2개씩 sampling한 결과 dataframe 만들기\n",
        "def make_combination_diff(length, species, data_frame):\n",
        "    before_file_path = []\n",
        "    after_file_path = []\n",
        "    time_delta = []\n",
        "\n",
        "    for i in range(length):\n",
        "      # sample 이용해서 dataframe에서 2개 뽑기\n",
        "      sample = data_frame[data_frame['species'] == species].sample(2)\n",
        "      # day가 더 큰 sample을 after\n",
        "      after = sample[sample['day'] == max(sample['day'])].reset_index(drop=True)\n",
        "      # day가 더 작은 sample을 before\n",
        "      before = sample[sample['day'] == min(sample['day'])].reset_index(drop=True)\n",
        "\n",
        "      before_file_path.append(before.iloc[0]['file_name'])\n",
        "      after_file_path.append(after.iloc[0]['file_name'])\n",
        "      delta = int(after.iloc[0]['day'] - before.iloc[0]['day'])\n",
        "      time_delta.append(delta)\n",
        "\n",
        "    combination_df = pd.DataFrame({\n",
        "        'before_file_path': before_file_path,\n",
        "        'after_file_path': after_file_path,\n",
        "        'time_delta': time_delta,\n",
        "    })\n",
        "\n",
        "    combination_df['species'] = species\n",
        "\n",
        "    return combination_df"
      ],
      "metadata": {
        "id": "g0uhes3zrVZZ"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 같은 종에서 2개씩 추출(같은 폴더가 아닌 것으로) Image augmentation)\n",
        "# 1000개 추출하여 8:2로 나누기\n",
        "bt_combination_diff = make_combination_diff(1000, 'bc', total_dataframe)\n",
        "lt_combination_diff = make_combination_diff(1000, 'lt', total_dataframe)\n",
        "\n",
        "bt_train_diff = bt_combination_diff.iloc[:800]\n",
        "bt_valid_diff = bt_combination_diff.iloc[800:]\n",
        "\n",
        "lt_train_diff = lt_combination_diff.iloc[:800]\n",
        "lt_valid_diff = lt_combination_diff.iloc[800:]\n",
        "\n",
        "train_set_diff = pd.concat([bt_train_diff, lt_train_diff])\n",
        "valid_set_diff = pd.concat([bt_valid_diff, lt_valid_diff])"
      ],
      "metadata": {
        "id": "_WevJI6lsiSp"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img = Image.open(total_dataframe['file_name'][0])\n",
        "print(img.size)\n",
        "print(img.mode)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ztz6Ae-xArQ",
        "outputId": "91dad629-1b14-42d9-cd78-a0aacce29033"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(224, 224)\n",
            "RGB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('x_train shape:', train_set.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pezhbAPDxAvv",
        "outputId": "a877572d-61e4-4ec3-df8d-761bed9786bf"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x_train shape: (1600, 4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_img_file_names = zip(train_set['before_file_path'], train_set['after_file_path'])\n",
        "\n",
        "train_before = []\n",
        "train_after = []\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "\n",
        "for before, after in train_img_file_names:\n",
        "    before_image = Image.open(before)\n",
        "    after_image = Image.open(after)\n",
        "\n",
        "    before_image = transform(before_image)\n",
        "    after_image = transform(after_image)\n",
        "\n",
        "    train_before.append(before_image)\n",
        "    train_after.append(after_image)\n",
        "\n",
        "train_before_np = np.zeros((1600,3,224, 224))\n",
        "train_after_np = np.zeros((1600,3,224, 224))\n",
        "\n",
        "for i in range(1600):\n",
        "    train_before_np[i] = train_before[i].numpy()\n",
        "    train_after_np[i] = train_after[i].numpy()"
      ],
      "metadata": {
        "id": "bmO_IIUB7JK1"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.save(\"/content/drive/MyDrive/ds_study/train_before.npy\", train_before_np)\n",
        "np.save(\"/content/drive/MyDrive/ds_study/train_after.npy\", train_after_np)\n",
        "np.save(\"/content/drive/MyDrive/ds_study/train_label.npy\", np.array(train_set['time_delta']))"
      ],
      "metadata": {
        "id": "nsdtT5S_P-Zp"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_gap = train_after_np - train_before_np\n",
        "np.save(\"/content/drive/MyDrive/ds_study/train_gap.npy\", train_gap)"
      ],
      "metadata": {
        "id": "moKC5D0s8xqX"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "valid_img_file_names = zip(valid_set['before_file_path'], valid_set['after_file_path'])\n",
        "\n",
        "valid_before = []\n",
        "valid_after = []\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "\n",
        "for before, after in valid_img_file_names:\n",
        "    before_image = Image.open(before)\n",
        "    after_image = Image.open(after)\n",
        "\n",
        "    before_image = transform(before_image)\n",
        "    after_image = transform(after_image)\n",
        "\n",
        "    valid_before.append(before_image)\n",
        "    valid_after.append(after_image)\n",
        "\n",
        "valid_before_np = np.zeros((400,3,224, 224))\n",
        "valid_after_np = np.zeros((400,3,224, 224))\n",
        "\n",
        "for i in range(400):\n",
        "    valid_before_np[i] = valid_before[i].numpy()\n",
        "    valid_after_np[i] = valid_after[i].numpy()"
      ],
      "metadata": {
        "id": "hoFufqkN_KGq"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.save(\"/content/drive/MyDrive/ds_study/valid_before.npy\", valid_before_np)\n",
        "np.save(\"/content/drive/MyDrive/ds_study/valid_after.npy\", valid_after_np)\n",
        "np.save(\"/content/drive/MyDrive/ds_study/valid_label.npy\", np.array(valid_set['time_delta']))"
      ],
      "metadata": {
        "id": "3MDWHSBvQY1H"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "valid_gap = valid_after_np - valid_before_np\n",
        "np.save(\"/content/drive/MyDrive/ds_study/valid_gap.npy\", valid_gap)"
      ],
      "metadata": {
        "id": "hVAojl5TC6Wv"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('valid shape:', valid_set.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KMXQ7JK2AlbQ",
        "outputId": "b21d1e54-681a-44f2-b4e5-5bbea2b59e27"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "valid shape: (400, 4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_set = pd.read_csv('/content/drive/MyDrive/ds_study/data/test_dataset/test_data.csv')\n",
        "test_set['l_root'] = test_set['before_file_path'].map(lambda x : '/content/drive/MyDrive/ds_study/data/test_dataset/' + x.split('_')[1] + '_RESIZE/' + x.split('_')[2])\n",
        "test_set['r_root'] = test_set['after_file_path'].map(lambda x : '/content/drive/MyDrive/ds_study/data/test_dataset/' + x.split('_')[1] + '_RESIZE/' + x.split('_')[2])\n",
        "test_set['before_file_path_new'] = test_set['l_root'] + '/' + test_set['before_file_path'] + '.png'\n",
        "test_set['after_file_path_new'] = test_set['r_root'] + '/' + test_set['after_file_path'] + '.png'"
      ],
      "metadata": {
        "id": "2T1MUFAoApXu"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_set.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "id": "eXsP1A0bBXDB",
        "outputId": "dfcf872d-09c3-4839-f69e-eba784def333"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-4312e2d0-ae8f-4a8f-b384-8f303431a595\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>idx</th>\n",
              "      <th>before_file_path</th>\n",
              "      <th>after_file_path</th>\n",
              "      <th>l_root</th>\n",
              "      <th>r_root</th>\n",
              "      <th>before_file_path_new</th>\n",
              "      <th>after_file_path_new</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>idx_LT_1003_00341</td>\n",
              "      <td>idx_LT_1003_00154</td>\n",
              "      <td>/content/drive/MyDrive/ds_study/data/test_data...</td>\n",
              "      <td>/content/drive/MyDrive/ds_study/data/test_data...</td>\n",
              "      <td>/content/drive/MyDrive/ds_study/data/test_data...</td>\n",
              "      <td>/content/drive/MyDrive/ds_study/data/test_data...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>idx_LT_1003_00592</td>\n",
              "      <td>idx_LT_1003_00687</td>\n",
              "      <td>/content/drive/MyDrive/ds_study/data/test_data...</td>\n",
              "      <td>/content/drive/MyDrive/ds_study/data/test_data...</td>\n",
              "      <td>/content/drive/MyDrive/ds_study/data/test_data...</td>\n",
              "      <td>/content/drive/MyDrive/ds_study/data/test_data...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>idx_BC_1100_00445</td>\n",
              "      <td>idx_BC_1100_00840</td>\n",
              "      <td>/content/drive/MyDrive/ds_study/data/test_data...</td>\n",
              "      <td>/content/drive/MyDrive/ds_study/data/test_data...</td>\n",
              "      <td>/content/drive/MyDrive/ds_study/data/test_data...</td>\n",
              "      <td>/content/drive/MyDrive/ds_study/data/test_data...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>idx_BC_1112_00229</td>\n",
              "      <td>idx_BC_1112_00105</td>\n",
              "      <td>/content/drive/MyDrive/ds_study/data/test_data...</td>\n",
              "      <td>/content/drive/MyDrive/ds_study/data/test_data...</td>\n",
              "      <td>/content/drive/MyDrive/ds_study/data/test_data...</td>\n",
              "      <td>/content/drive/MyDrive/ds_study/data/test_data...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>idx_LT_1088_00681</td>\n",
              "      <td>idx_LT_1088_00698</td>\n",
              "      <td>/content/drive/MyDrive/ds_study/data/test_data...</td>\n",
              "      <td>/content/drive/MyDrive/ds_study/data/test_data...</td>\n",
              "      <td>/content/drive/MyDrive/ds_study/data/test_data...</td>\n",
              "      <td>/content/drive/MyDrive/ds_study/data/test_data...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4312e2d0-ae8f-4a8f-b384-8f303431a595')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-4312e2d0-ae8f-4a8f-b384-8f303431a595 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-4312e2d0-ae8f-4a8f-b384-8f303431a595');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   idx  ...                                after_file_path_new\n",
              "0    0  ...  /content/drive/MyDrive/ds_study/data/test_data...\n",
              "1    1  ...  /content/drive/MyDrive/ds_study/data/test_data...\n",
              "2    2  ...  /content/drive/MyDrive/ds_study/data/test_data...\n",
              "3    3  ...  /content/drive/MyDrive/ds_study/data/test_data...\n",
              "4    4  ...  /content/drive/MyDrive/ds_study/data/test_data...\n",
              "\n",
              "[5 rows x 7 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 35
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: Runtime no longer has a reference to this dataframe, please re-run this cell and try again.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_img_file_names = zip(test_set['before_file_path_new'], test_set['after_file_path_new'])\n",
        "\n",
        "test_before = []\n",
        "test_after = []\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "\n",
        "for before, after in test_img_file_names:\n",
        "    before_image = Image.open(before)\n",
        "    after_image = Image.open(after)\n",
        "\n",
        "    before_image = transform(before_image)\n",
        "    after_image = transform(after_image)\n",
        "\n",
        "    test_before.append(before_image)\n",
        "    test_after.append(after_image)\n",
        "\n",
        "test_before_np = np.zeros((3960,3,224, 224))\n",
        "test_after_np = np.zeros((3960,3,224, 224))\n",
        "\n",
        "for i in range(3960):\n",
        "    test_before_np[i] = test_before[i].numpy()\n",
        "    test_after_np[i] = test_after[i].numpy()\n",
        "\n"
      ],
      "metadata": {
        "id": "VvRr0XsUBXH9"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.save(\"/content/drive/MyDrive/ds_study/test_before.npy\", test_before_np)\n",
        "np.save(\"/content/drive/MyDrive/ds_study/test_after.npy\", test_after_np)"
      ],
      "metadata": {
        "id": "2tcvts5VQmYR"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_gap = test_before_np - test_after_np\n",
        "np.save(\"/content/drive/MyDrive/ds_study/test_gap.npy\", test_gap)"
      ],
      "metadata": {
        "id": "sxvm2ccOBXLl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_label_data = pd.read_csv('/content/drive/MyDrive/ds_study/data/sample_submission.csv')\n",
        "np.save(\"/content/drive/MyDrive/ds_study/test_label.npy\", np.array(test_label_data['time_delta']))"
      ],
      "metadata": {
        "id": "SXZ6O0ZPBXMp"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_x = np.load(\"/content/drive/MyDrive/ds_study/train_gap.npy\")\n",
        "train_y = "
      ],
      "metadata": {
        "id": "wW62vOW-BXPA"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(test_gap)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PfutQQzqBXRH",
        "outputId": "f98b8862-4d93-4a8e-eff1-0e5994f19ea6"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3960"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_dataset = KistDataset(test_set, is_test = True)\n",
        "test_data_loader = DataLoader(test_dataset, batch_size = 64)"
      ],
      "metadata": {
        "id": "WvoX7bhCBXFn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "eht7tpZABXTK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lXsO6OyvFiJz"
      },
      "source": [
        "import datetime\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.losses import categorical_crossentropy\n",
        "from tensorflow.keras.layers import Dense, Flatten, Conv2D, AveragePooling2D\n",
        "\n",
        "from tensorflow.keras import datasets\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "from __future__ import absolute_import, division, print_function, unicode_literals"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}