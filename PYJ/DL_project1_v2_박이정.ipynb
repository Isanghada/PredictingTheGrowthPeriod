{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "\bDL_project1_v2_박이정.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyO7k/JQZ6uFXcttJ/bW6ahZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/happyfranc/ml_project/blob/main/%08DL_project1_v2_%EB%B0%95%EC%9D%B4%EC%A0%95.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "생육 기간 예측 프로젝트\n",
        "\n",
        "목적 및 배경 : 한 쌍의 이미지를 입력받아 작물의 생육 기간을 예측하는 모델 개발\n",
        "\n",
        "데이터 정보 및 학습 진행 방식 : DACON \"생육 기간 예측 경진대회\" 데이터\n",
        "\n",
        "2개 작물(청경채, 적상추)에 대한 생육 기간 경과일자별 이미지 데이터 저장\n",
        "- 학습 : 753개(청경채 353개, 적상추 400개)\n",
        "- 테스트 : 307개(청경채 139개, 적상추 168개)\n",
        "\n",
        "\n",
        "작물별 이미지 2장씩을 다양하게 조합하여 2장의 이미지간 경과일을 기준으로 학습 및 평가 진행 예정\n",
        "\n",
        "모델 평가 기준 : RMSE(Root Mean Squared Error)"
      ],
      "metadata": {
        "id": "Mgcu5w7135g5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "_mnxyFv9HteI"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "from glob import glob\n",
        "import os\n",
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torch import optim\n",
        "from torch import nn\n",
        "from torchvision.transforms import ToTensor\n",
        "from torchvision import transforms\n",
        "from tqdm.auto import tqdm"
      ],
      "metadata": {
        "id": "NX6D2-7kG0eR"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "p7oLel0vHv8x",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "559c8206-2423-4c16-cbb6-f532821b29e8"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# seed 고정\n",
        "def seed_everything(seed):\n",
        "    # 파이토치 및 넘파이, random 등 관련 모듈에 대한 seed 일괄 설정\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)  # multi-GPU\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "    np.random.seed(seed)\n",
        "    random.seed(seed)\n",
        "\n",
        "seed_everything(2048)"
      ],
      "metadata": {
        "id": "6A8ouGFZHv_4"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "is_cuda = torch.cuda.is_available()\n",
        "device = torch.device('cuda' if is_cuda else 'cpu')\n",
        "\n",
        "lr = 0.00005\n",
        "epochs = 10\n",
        "batch_size = 64\n",
        "valid_batch_size = 50 ## 확인"
      ],
      "metadata": {
        "id": "dSXDdpsoHwCe"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 파일 path\n",
        "train_path = '/content/drive/MyDrive/ds_study/data/train_dataset'\n",
        "test_path = '/content/drive/MyDrive/ds_study/data/test_dataset'"
      ],
      "metadata": {
        "id": "_2nCRwJ0HwEz"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data resize 저장 함수\n",
        "def data_resize(species_nm,root_path):\n",
        "  os.mkdir(root_path +'/'+ species_nm + '_resize')\n",
        "  for sub_path in os.listdir(root_path +'/'+ species_nm): # 서브 폴더 생성\n",
        "    os.mkdir(root_path +'/'+ species_nm + '_resize/' + sub_path)\n",
        "    for image_path in glob(root_path +'/'+ species_nm + '/' + sub_path + '/*'): # 이미지 resize 및 저장\n",
        "      image_file_name = image_path.split('/')[-1]\n",
        "      img = Image.open(image_path)\n",
        "      img = img.resize((224, 224))\n",
        "      img.save(root_path +'/'+ species_nm + '_resize/' + sub_path + '/' + image_file_name)"
      ],
      "metadata": {
        "id": "y3xNKo_xwzG5"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# BC train\n",
        "#data_resize('BC',train_path)"
      ],
      "metadata": {
        "id": "foQikkVfxAiJ"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# LT train\n",
        "#data_resize('LT',train_path)"
      ],
      "metadata": {
        "id": "y9kr7cD4xAkw"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# BC test\n",
        "#data_resize('BC',test_path)"
      ],
      "metadata": {
        "id": "SS8LO-VxxAnG"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# LT test\n",
        "#data_resize('LT',test_path)"
      ],
      "metadata": {
        "id": "RUNnFaXBxAo7"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(glob(train_path + '/BC/**/**')),len(glob(train_path + '/BC_resize/**/**')))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mH6NEvT3d-RD",
        "outputId": "4910c046-6443-40c0-9415-2ab2c3e3f50c"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "353 353\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(glob(train_path + '/LT/**/**')),len(glob(train_path + '/LT_resize/**/**')))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4A-vtL5Vd-Ta",
        "outputId": "993045c5-c140-4719-afe5-8e3190b2c2e0"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "400 400\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 파일 이름에서 날짜 추출\n",
        "def extract_day(file_name):\n",
        "  day = int(file_name.split('.')[-2][-2:])\n",
        "  return day"
      ],
      "metadata": {
        "id": "jSvH9lziHwHb"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 파일 이름에서 날짜 추출 후 array 파일로 만들기\n",
        "def make_day_array(file_name):\n",
        "  day_array = np.array([extract_day(file_name) for file_name in file_name])\n",
        "  return day_array"
      ],
      "metadata": {
        "id": "jLFZcUwQankL"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# image path array 생성\n",
        "def make_image_path_array(root_path):\n",
        "  bc_directories = glob(root_path + '/BC_resize/*')\n",
        "  lt_directories = glob(root_path + '/LT_resize/*')\n",
        "  \n",
        "  # bc 이미지 확인\n",
        "  bc_image_path = []  \n",
        "  for bc_path in bc_directories:\n",
        "    images = glob(bc_path + '/*.png')\n",
        "    bc_image_path.extend(images)\n",
        "    print(len(bc_image_path))\n",
        "\n",
        "  # lt 이미지 확인\n",
        "  lt_image_path = []  \n",
        "  for lt_path in lt_directories:\n",
        "    images = glob(lt_path + '/*.png')\n",
        "    lt_image_path.extend(images)\n",
        "    print(len(lt_image_path))\n",
        "    \n",
        "  return bc_image_path, lt_image_path"
      ],
      "metadata": {
        "id": "HFtRt2-FMuRC"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# DataFrame 만들기(columns = 파일 이름, 일자, 종)\n",
        "def make_dataframe(root_path):\n",
        "  bc_image_path, lt_image_path = make_image_path_array(root_path) # 데이터 저장 경로 입력 후 파일 리스트 생성\n",
        "  bc_day_array = make_day_array(bc_image_path) # bc 파일 이름에서 날짜 추출 후 array 만들기\n",
        "  lt_day_array = make_day_array(lt_image_path) # lt 파일 이름에서 날짜 추출 후 array 만들기\n",
        "\n",
        "  bc_df = pd.DataFrame({\"file_name\": bc_image_path, \n",
        "                        \"day\" : bc_day_array})\n",
        "\n",
        "  bc_df['species'] = 'bc' # 종 추가\n",
        "\n",
        "\n",
        "  lt_df = pd.DataFrame({\"file_name\": lt_image_path,\n",
        "                        \"day\" : lt_day_array})\n",
        "\n",
        "  lt_df['species'] = 'lt' # 종 추가\n",
        "\n",
        "  total_data_frame = pd.concat([bc_df, lt_df]).reset_index(drop=True)\n",
        "\n",
        "  return total_data_frame"
      ],
      "metadata": {
        "id": "mHsltK2YMuUI"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#length만큼 2개씩 sampling한 결과 dataframe 만들기\n",
        "def make_combination(length, species, data_frame, direct_name):\n",
        "    before_file_path = []\n",
        "    after_file_path = []\n",
        "    time_delta = []\n",
        "\n",
        "    for i in range(length):\n",
        "      # 하위 폴더 중 랜덤하게 선택\n",
        "      direct = random.randrange(0,len(direct_name))\n",
        "      # 위에서 결정된 폴더를 선택\n",
        "      temp = data_frame[data_frame['version'] == direct_name[direct]]\n",
        "\n",
        "      # sample 이용해서 dataframe에서 2개 뽑기\n",
        "      sample = temp[temp['species'] == species].sample(2)\n",
        "      # day가 더 큰 sample을 after\n",
        "      after = sample[sample['day'] == max(sample['day'])].reset_index(drop=True)\n",
        "      # day가 더 작은 sample을 before\n",
        "      before = sample[sample['day'] == min(sample['day'])].reset_index(drop=True)\n",
        "\n",
        "      before_file_path.append(before.iloc[0]['file_name'])\n",
        "      after_file_path.append(after.iloc[0]['file_name'])\n",
        "      delta = int(after.iloc[0]['day'] - before.iloc[0]['day'])\n",
        "      time_delta.append(delta)\n",
        "\n",
        "    combination_df = pd.DataFrame({\n",
        "        'before_file_path': before_file_path,\n",
        "        'after_file_path': after_file_path,\n",
        "        'time_delta': time_delta,\n",
        "    })\n",
        "\n",
        "    combination_df['species'] = species\n",
        "\n",
        "    return combination_df"
      ],
      "metadata": {
        "id": "nrqtvt9uZGxE"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# BC 폴더와 LT 폴더에 있는 하위 폴더를 저장한다.\n",
        "bc_direct = glob(train_path + '/BC_resize/*')\n",
        "bc_direct_name = [x[-5:] for x in bc_direct]\n",
        "print(bc_direct_name)\n",
        "lt_direct = glob(train_path + '/LT_resize/*')\n",
        "lt_direct_name = [x[-5:] for x in lt_direct]\n",
        "print(lt_direct_name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TD7JFmbDbrZn",
        "outputId": "e7409e1f-5cae-4fdf-d538-06ba4e584e48"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['BC_09', 'BC_06', 'BC_07', 'BC_01', 'BC_02', 'BC_08', 'BC_04', 'BC_05', 'BC_03']\n",
            "['LT_05', 'LT_03', 'LT_02', 'LT_04', 'LT_00', 'LT_07', 'LT_09', 'LT_08', 'LT_01', 'LT_06']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 하위 폴더에 있는 이미지들을 하위 폴더 이름과 매칭시켜서 저장한다.\n",
        "bc_images = {key : glob(name + '/*.png') for key,name in zip(bc_direct_name, bc_direct)}\n",
        "lt_images = {key : glob(name + '/*.png') for key,name in zip(lt_direct_name, lt_direct)}"
      ],
      "metadata": {
        "id": "RbkDORLOo06e"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 하위 폴더에 있는 이미지들에서 날짜 정보만 따로 저장한다.\n",
        "bc_dayes = {key : make_day_array(bc_images[key]) for key in bc_direct_name}\n",
        "lt_dayes = {key : make_day_array(lt_images[key]) for key in lt_direct_name}"
      ],
      "metadata": {
        "id": "btGupB0upP_4"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bc_dfs = []\n",
        "for i in bc_direct_name:\n",
        "    bc_df = pd.DataFrame({\n",
        "        'file_name':bc_images[i],\n",
        "        'day':bc_dayes[i],\n",
        "        'species':'bc',\n",
        "        'version':i\n",
        "    })\n",
        "    bc_dfs.append(bc_df)\n",
        "    \n",
        "lt_dfs = []\n",
        "for i in lt_direct_name:\n",
        "    lt_df = pd.DataFrame({\n",
        "        'file_name':lt_images[i],\n",
        "        'day':lt_dayes[i],\n",
        "        'species':'lt',\n",
        "        'version':i\n",
        "    })\n",
        "    lt_dfs.append(lt_df)"
      ],
      "metadata": {
        "id": "qTjwxQSUo09E"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터셋 만들기\n",
        "# 1000개, 8 : 2\n",
        "bc_dataframe = pd.concat(bc_dfs).reset_index(drop=True)\n",
        "lt_dataframe = pd.concat(lt_dfs).reset_index(drop=True)\n",
        "total_dataframe = pd.concat([bc_dataframe, lt_dataframe]).reset_index(drop=True)\n",
        "\n",
        "\n",
        "bc_combination = make_combination(1000, 'bc', total_dataframe, bc_direct_name)\n",
        "lt_combination = make_combination(1000, 'lt', total_dataframe, lt_direct_name)\n",
        "\n",
        "bc_train = bc_combination.iloc[:800]\n",
        "bc_valid = bc_combination.iloc[800:]\n",
        "\n",
        "lt_train = lt_combination.iloc[:800]\n",
        "lt_valid = lt_combination.iloc[800:]\n",
        "\n",
        "train_set = pd.concat([bc_train, lt_train])\n",
        "valid_set = pd.concat([bc_valid, lt_valid])"
      ],
      "metadata": {
        "id": "eiqn4ccvMuf6"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#length만큼 2개씩 sampling한 결과 dataframe 만들기\n",
        "def make_combination_diff(length, species, data_frame):\n",
        "    before_file_path = []\n",
        "    after_file_path = []\n",
        "    time_delta = []\n",
        "\n",
        "    for i in range(length):\n",
        "      # sample 이용해서 dataframe에서 2개 뽑기\n",
        "      sample = data_frame[data_frame['species'] == species].sample(2)\n",
        "      # day가 더 큰 sample을 after\n",
        "      after = sample[sample['day'] == max(sample['day'])].reset_index(drop=True)\n",
        "      # day가 더 작은 sample을 before\n",
        "      before = sample[sample['day'] == min(sample['day'])].reset_index(drop=True)\n",
        "\n",
        "      before_file_path.append(before.iloc[0]['file_name'])\n",
        "      after_file_path.append(after.iloc[0]['file_name'])\n",
        "      delta = int(after.iloc[0]['day'] - before.iloc[0]['day'])\n",
        "      time_delta.append(delta)\n",
        "\n",
        "    combination_df = pd.DataFrame({\n",
        "        'before_file_path': before_file_path,\n",
        "        'after_file_path': after_file_path,\n",
        "        'time_delta': time_delta,\n",
        "    })\n",
        "\n",
        "    combination_df['species'] = species\n",
        "\n",
        "    return combination_df"
      ],
      "metadata": {
        "id": "g0uhes3zrVZZ"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 같은 종에서 2개씩 추출(같은 폴더가 아닌 것으로) Image augmentation)\n",
        "# 1000개 추출하여 8:2로 나누기\n",
        "bt_combination_diff = make_combination_diff(1000, 'bc', total_dataframe)\n",
        "lt_combination_diff = make_combination_diff(1000, 'lt', total_dataframe)\n",
        "\n",
        "bt_train_diff = bt_combination_diff.iloc[:800]\n",
        "bt_valid_diff = bt_combination_diff.iloc[800:]\n",
        "\n",
        "lt_train_diff = lt_combination_diff.iloc[:800]\n",
        "lt_valid_diff = lt_combination_diff.iloc[800:]\n",
        "\n",
        "train_set_diff = pd.concat([bt_train_diff, lt_train_diff])\n",
        "valid_set_diff = pd.concat([bt_valid_diff, lt_valid_diff])"
      ],
      "metadata": {
        "id": "_WevJI6lsiSp"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train, valid 데이터 csv파일로 저장 \n",
        "train_set.to_csv('/content/drive/MyDrive/ds_study/train_data.csv', index=False)\n",
        "valid_set.to_csv('/content/drive/MyDrive/ds_study/valid_data.csv', index=False)"
      ],
      "metadata": {
        "id": "W01qbhEJa8He"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train, valid 데이터 csv파일 불러오기\n",
        "train_data = pd.read_csv('/content/drive/MyDrive/ds_study/train_data.csv')\n",
        "valid_data = pd.read_csv('/content/drive/MyDrive/ds_study/valid_data.csv')"
      ],
      "metadata": {
        "id": "YgR1hzVBbQcS"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img = Image.open(total_dataframe['file_name'][0])\n",
        "print(img.size)\n",
        "print(img.mode)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ztz6Ae-xArQ",
        "outputId": "91dad629-1b14-42d9-cd78-a0aacce29033"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(224, 224)\n",
            "RGB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('x_train shape:', train_set.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pezhbAPDxAvv",
        "outputId": "a877572d-61e4-4ec3-df8d-761bed9786bf"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x_train shape: (1600, 4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_img_file_names = zip(train_set['before_file_path'], train_set['after_file_path'])\n",
        "\n",
        "train_before = []\n",
        "train_after = []\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "\n",
        "for before, after in train_img_file_names:\n",
        "    before_image = Image.open(before)\n",
        "    after_image = Image.open(after)\n",
        "\n",
        "    before_image = transform(before_image)\n",
        "    after_image = transform(after_image)\n",
        "\n",
        "    train_before.append(before_image)\n",
        "    train_after.append(after_image)\n",
        "\n",
        "train_before_np = np.zeros((1600,3,224, 224))\n",
        "train_after_np = np.zeros((1600,3,224, 224))\n",
        "\n",
        "for i in range(1600):\n",
        "    train_before_np[i] = train_before[i].numpy()\n",
        "    train_after_np[i] = train_after[i].numpy()"
      ],
      "metadata": {
        "id": "bmO_IIUB7JK1"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.save(\"/content/drive/MyDrive/ds_study/train_before.npy\", train_before_np)\n",
        "np.save(\"/content/drive/MyDrive/ds_study/train_after.npy\", train_after_np)\n",
        "np.save(\"/content/drive/MyDrive/ds_study/train_label.npy\", np.array(train_set['time_delta']))"
      ],
      "metadata": {
        "id": "nsdtT5S_P-Zp"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_gap = train_after_np - train_before_np\n",
        "np.save(\"/content/drive/MyDrive/ds_study/train_gap.npy\", train_gap)"
      ],
      "metadata": {
        "id": "moKC5D0s8xqX"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "valid_img_file_names = zip(valid_set['before_file_path'], valid_set['after_file_path'])\n",
        "\n",
        "valid_before = []\n",
        "valid_after = []\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "\n",
        "for before, after in valid_img_file_names:\n",
        "    before_image = Image.open(before)\n",
        "    after_image = Image.open(after)\n",
        "\n",
        "    before_image = transform(before_image)\n",
        "    after_image = transform(after_image)\n",
        "\n",
        "    valid_before.append(before_image)\n",
        "    valid_after.append(after_image)\n",
        "\n",
        "valid_before_np = np.zeros((400,3,224, 224))\n",
        "valid_after_np = np.zeros((400,3,224, 224))\n",
        "\n",
        "for i in range(400):\n",
        "    valid_before_np[i] = valid_before[i].numpy()\n",
        "    valid_after_np[i] = valid_after[i].numpy()"
      ],
      "metadata": {
        "id": "hoFufqkN_KGq"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.save(\"/content/drive/MyDrive/ds_study/valid_before.npy\", valid_before_np)\n",
        "np.save(\"/content/drive/MyDrive/ds_study/valid_after.npy\", valid_after_np)\n",
        "np.save(\"/content/drive/MyDrive/ds_study/valid_label.npy\", np.array(valid_set['time_delta']))"
      ],
      "metadata": {
        "id": "3MDWHSBvQY1H"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "valid_gap = valid_after_np - valid_before_np\n",
        "np.save(\"/content/drive/MyDrive/ds_study/valid_gap.npy\", valid_gap)"
      ],
      "metadata": {
        "id": "hVAojl5TC6Wv"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('valid shape:', valid_set.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KMXQ7JK2AlbQ",
        "outputId": "b21d1e54-681a-44f2-b4e5-5bbea2b59e27"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "valid shape: (400, 4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_set = pd.read_csv('/content/drive/MyDrive/ds_study/data/test_dataset/test_data.csv')\n",
        "test_set['l_root'] = test_set['before_file_path'].map(lambda x : '/content/drive/MyDrive/ds_study/data/test_dataset/' + x.split('_')[1] + '_RESIZE/' + x.split('_')[2])\n",
        "test_set['r_root'] = test_set['after_file_path'].map(lambda x : '/content/drive/MyDrive/ds_study/data/test_dataset/' + x.split('_')[1] + '_RESIZE/' + x.split('_')[2])\n",
        "test_set['before_file_path_new'] = test_set['l_root'] + '/' + test_set['before_file_path'] + '.png'\n",
        "test_set['after_file_path_new'] = test_set['r_root'] + '/' + test_set['after_file_path'] + '.png'"
      ],
      "metadata": {
        "id": "2T1MUFAoApXu"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_set.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "id": "eXsP1A0bBXDB",
        "outputId": "dfcf872d-09c3-4839-f69e-eba784def333"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-4312e2d0-ae8f-4a8f-b384-8f303431a595\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>idx</th>\n",
              "      <th>before_file_path</th>\n",
              "      <th>after_file_path</th>\n",
              "      <th>l_root</th>\n",
              "      <th>r_root</th>\n",
              "      <th>before_file_path_new</th>\n",
              "      <th>after_file_path_new</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>idx_LT_1003_00341</td>\n",
              "      <td>idx_LT_1003_00154</td>\n",
              "      <td>/content/drive/MyDrive/ds_study/data/test_data...</td>\n",
              "      <td>/content/drive/MyDrive/ds_study/data/test_data...</td>\n",
              "      <td>/content/drive/MyDrive/ds_study/data/test_data...</td>\n",
              "      <td>/content/drive/MyDrive/ds_study/data/test_data...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>idx_LT_1003_00592</td>\n",
              "      <td>idx_LT_1003_00687</td>\n",
              "      <td>/content/drive/MyDrive/ds_study/data/test_data...</td>\n",
              "      <td>/content/drive/MyDrive/ds_study/data/test_data...</td>\n",
              "      <td>/content/drive/MyDrive/ds_study/data/test_data...</td>\n",
              "      <td>/content/drive/MyDrive/ds_study/data/test_data...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>idx_BC_1100_00445</td>\n",
              "      <td>idx_BC_1100_00840</td>\n",
              "      <td>/content/drive/MyDrive/ds_study/data/test_data...</td>\n",
              "      <td>/content/drive/MyDrive/ds_study/data/test_data...</td>\n",
              "      <td>/content/drive/MyDrive/ds_study/data/test_data...</td>\n",
              "      <td>/content/drive/MyDrive/ds_study/data/test_data...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>idx_BC_1112_00229</td>\n",
              "      <td>idx_BC_1112_00105</td>\n",
              "      <td>/content/drive/MyDrive/ds_study/data/test_data...</td>\n",
              "      <td>/content/drive/MyDrive/ds_study/data/test_data...</td>\n",
              "      <td>/content/drive/MyDrive/ds_study/data/test_data...</td>\n",
              "      <td>/content/drive/MyDrive/ds_study/data/test_data...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>idx_LT_1088_00681</td>\n",
              "      <td>idx_LT_1088_00698</td>\n",
              "      <td>/content/drive/MyDrive/ds_study/data/test_data...</td>\n",
              "      <td>/content/drive/MyDrive/ds_study/data/test_data...</td>\n",
              "      <td>/content/drive/MyDrive/ds_study/data/test_data...</td>\n",
              "      <td>/content/drive/MyDrive/ds_study/data/test_data...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4312e2d0-ae8f-4a8f-b384-8f303431a595')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-4312e2d0-ae8f-4a8f-b384-8f303431a595 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-4312e2d0-ae8f-4a8f-b384-8f303431a595');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   idx  ...                                after_file_path_new\n",
              "0    0  ...  /content/drive/MyDrive/ds_study/data/test_data...\n",
              "1    1  ...  /content/drive/MyDrive/ds_study/data/test_data...\n",
              "2    2  ...  /content/drive/MyDrive/ds_study/data/test_data...\n",
              "3    3  ...  /content/drive/MyDrive/ds_study/data/test_data...\n",
              "4    4  ...  /content/drive/MyDrive/ds_study/data/test_data...\n",
              "\n",
              "[5 rows x 7 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 35
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: Runtime no longer has a reference to this dataframe, please re-run this cell and try again.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_img_file_names = zip(test_set['before_file_path_new'], test_set['after_file_path_new'])\n",
        "\n",
        "test_before = []\n",
        "test_after = []\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "\n",
        "for before, after in test_img_file_names:\n",
        "    before_image = Image.open(before)\n",
        "    after_image = Image.open(after)\n",
        "\n",
        "    before_image = transform(before_image)\n",
        "    after_image = transform(after_image)\n",
        "\n",
        "    test_before.append(before_image)\n",
        "    test_after.append(after_image)\n",
        "\n",
        "test_before_np = np.zeros((3960,3,224, 224))\n",
        "test_after_np = np.zeros((3960,3,224, 224))\n",
        "\n",
        "for i in range(3960):\n",
        "    test_before_np[i] = test_before[i].numpy()\n",
        "    test_after_np[i] = test_after[i].numpy()\n",
        "\n"
      ],
      "metadata": {
        "id": "VvRr0XsUBXH9"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.save(\"/content/drive/MyDrive/ds_study/test_before.npy\", test_before_np)\n",
        "np.save(\"/content/drive/MyDrive/ds_study/test_after.npy\", test_after_np)"
      ],
      "metadata": {
        "id": "2tcvts5VQmYR"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_gap = test_before_np - test_after_np\n",
        "np.save(\"/content/drive/MyDrive/ds_study/test_gap.npy\", test_gap)"
      ],
      "metadata": {
        "id": "sxvm2ccOBXLl"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_label_data = pd.read_csv('/content/drive/MyDrive/ds_study/data/sample_submission.csv')\n",
        "np.save(\"/content/drive/MyDrive/ds_study/test_label.npy\", np.array(test_label_data['time_delta']))"
      ],
      "metadata": {
        "id": "SXZ6O0ZPBXMp"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 사용자 정의 데이터셋 클래스\n",
        "class ImageDataset(Dataset):\n",
        "  def __init__(self, combination_df, is_test=None):\n",
        "    self.combination_df = combination_df\n",
        "    self.transform = transforms.Compose([\n",
        "      transforms.Resize(224), \n",
        "      transforms.ToTensor()\n",
        "      ])\n",
        "    \n",
        "  def __len__(self):\n",
        "    return len(self.combination_df)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    before_image = Image.open(self.combination_df.iloc[idx]['before_image_path'])\n",
        "    after_image = Image.open(self.combination_df.iloc[idx]['after_image_path'])\n",
        "\n",
        "    before_image = self.transform(before_image)\n",
        "    after_image = self.transform(after_image)\n",
        "\n",
        "    time_delta = self.combination_df.iloc[idx]['time_delta']\n",
        "\n",
        "    return before_image, after_image, time_delta"
      ],
      "metadata": {
        "id": "WgGuCcZmcnlx"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = ImageDataset(train_data)\n",
        "valid_dataset = ImageDataset(valid_data)"
      ],
      "metadata": {
        "id": "WSVsLS-ecnqv"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "valid_loader = DataLoader(valid_dataset, batch_size=valid_batch_size)"
      ],
      "metadata": {
        "id": "UpPzElHTdYU_"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 모델링"
      ],
      "metadata": {
        "id": "cM-uPvYIRtLF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_x = np.load(\"/content/drive/MyDrive/ds_study/train_gap.npy\")\n",
        "train_y = np.load(\"/content/drive/MyDrive/ds_study/train_label.npy\")\n",
        "\n",
        "valid_x = np.load(\"/content/drive/MyDrive/ds_study/valid_gap.npy\")\n",
        "valid_y = np.load(\"/content/drive/MyDrive/ds_study/valid_label.npy\")\n",
        "\n",
        "test_x = np.load(\"/content/drive/MyDrive/ds_study/test_gap.npy\")\n",
        "test_y = np.load(\"/content/drive/MyDrive/ds_study/test_label.npy\")"
      ],
      "metadata": {
        "id": "wW62vOW-BXPA"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lXsO6OyvFiJz"
      },
      "source": [
        "import datetime\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras import datasets, layers, models\n",
        "from tensorflow.keras.losses import categorical_crossentropy\n",
        "#from tensorflow.keras.layers import Dense, Flatten, Conv2D, AveragePooling2D\n",
        "\n",
        "from tensorflow.keras import datasets\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import transforms"
      ],
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "합성곱 층 만들기\n",
        "아래 6줄의 코드에서 Conv2D와 MaxPooling2D 층을 쌓는 일반적인 패턴으로 합성곱 층을 정의합니다.\n",
        "\n",
        "CNN은 배치(batch) 크기를 제외하고 (이미지 높이, 이미지 너비, 컬러 채널) 크기의 텐서(tensor)를 입력으로 받습니다. MNIST 데이터는 (흑백 이미지이기 때문에) 컬러 채널(channel)이 하나지만 컬러 이미지는 (R,G,B) 세 개의 채널을 가집니다. 이 예에서는 MNIST 이미지 포맷인 (28, 28, 1) 크기의 입력을 처리하는 CNN을 정의하겠습니다. 이 값을 첫 번째 층의 input_shape 매개변수로 전달합니다.\n",
        "\n",
        "1) 128px * 128px * 3 color채널 데이터(이미지)를 32개의 3x3 필터(kernel)로 합성곱(convolution) 실행\n",
        "\n",
        "2) max pooling을 통해 이미지 사이즈를 축소 (노드의 수는 증가하게 됨)\n",
        "\n",
        "3) 1)~2)의 과정을 반복, 이 때 필터의 개수는 2배로 증가시키는 것이 일반적\n",
        "\n",
        "4) 이미지의 크기가 4*4 또는 6*6 정도로 작아지면 합성곱-pooling의 반복을 중단\n",
        "\n",
        "5) 이미지 데이터를 flatten (일차원 배열로 변형)\n",
        "\n",
        "6) dense layer를 통해 늘어난 node의 수를 축소, 이 때의 parameter는 적절한 크기로 설정 (이 프로그램에서는 flatten시 parameter 크기가 100만개 이상이어서 512로 설정)\n",
        "\n",
        "7) 마지막 dense layer는 출력 노드를 5개로 설정(label이 5개의 렌더링 parameter 값이기 때문), activation 함수는 sigmoid 를 사용하여 출력 값을 0~1 사이의 값으로 고정"
      ],
      "metadata": {
        "id": "WLOvThmrSruI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# tensorflow.keras LeNet\n",
        "def build_model():\n",
        "    model = keras.Sequential([\n",
        "        layers.Conv2D(32, (3,3), activation='relu', input_shape=(128,128,3)),\n",
        "        layers.MaxPooling2D((2,2)),\n",
        "        layers.Conv2D(64, (3,3), activation='relu'),\n",
        "        layers.MaxPooling2D((2,2)),\n",
        "        layers.Conv2D(128, (3,3), activation='relu'),\n",
        "        layers.MaxPooling2D((2,2)),\n",
        "        layers.Conv2D(256, (3,3), activation='relu'),\n",
        "        layers.MaxPooling2D((2,2)),\n",
        "        layers.Conv2D(512, (3,3), activation='relu'),\n",
        "        layers.Flatten(),\n",
        "        layers.Dense(512, activation='relu'),\n",
        "        layers.Dense(512, activation='relu'),\n",
        "        layers.Dense(1)\n",
        "    ])\n",
        "    \n",
        "    optimizer = tf.keras.optimizers.RMSprop(0.0001)\n",
        "    \n",
        "    model.compile(loss='mse',\n",
        "                  optimizer=optimizer,\n",
        "                  metrics=['mae', 'mse'])\n",
        "    return model"
      ],
      "metadata": {
        "id": "AGv78FxxSHTT"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_x.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-9CbcCRfSHWJ",
        "outputId": "2893033e-4d84-4461-8e72-f6b87b35d2e8"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1600, 3, 224, 224)"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "위에서 Conv2D와 MaxPooling2D 층의 출력은 (높이, 너비, 채널) 크기의 3D 텐서입니다. 높이와 너비 차원은 네트워크가 깊어질수록 감소하는 경향을 가집니다. Conv2D 층에서 출력 채널의 수는 첫 번째 매개변수에 의해 결정됩니다(예를 들면, 32 또는 64). 일반적으로 높이와 너비가 줄어듦에 따라 (계산 비용 측면에서) Conv2D 층의 출력 채널을 늘릴 수 있습니다."
      ],
      "metadata": {
        "id": "nqx10St9TwnG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t1L_s1eFSHZG",
        "outputId": "e6c4ffec-493a-4efb-da54-4dba809a09ca"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_3 (Conv2D)           (None, 254, 254, 32)      896       \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 127, 127, 32)     0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_4 (Conv2D)           (None, 125, 125, 64)      18496     \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPooling  (None, 62, 62, 64)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_5 (Conv2D)           (None, 60, 60, 64)        36928     \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 230400)            0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 64)                14745664  \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 14,801,984\n",
            "Trainable params: 14,801,984\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = build_model()"
      ],
      "metadata": {
        "id": "GIYNpJ_HXYet"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 에포크가 끝날 때마다 점(.)을 출력해 훈련 진행 과정을 표시합니다\n",
        "class PrintDot(keras.callbacks.Callback):\n",
        "  def on_epoch_end(self, epoch, logs):\n",
        "    if epoch % 100 == 0: print('')\n",
        "    print('.', end='')\n",
        "\n",
        "EPOCHS = 100\n",
        "\n",
        "history = model.fit(\n",
        "  train_x, train_y,\n",
        "  epochs=EPOCHS, validation_split = 0.2, verbose=0,\n",
        "  callbacks=[PrintDot()])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 607
        },
        "id": "murKxFAmSHbn",
        "outputId": "2ed91d5f-0ac4-4ccb-cb67-86afca799b6c"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-74-900bbb0d57f8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m   \u001b[0mtrain_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m   \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m   callbacks=[PrintDot()])\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mautograph_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1127\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1128\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1129\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1130\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1131\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 878, in train_function  *\n        return step_function(self, iterator)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 867, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 860, in run_step  **\n        outputs = model.train_step(data)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 808, in train_step\n        y_pred = self(x, training=True)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/input_spec.py\", line 263, in assert_input_compatibility\n        raise ValueError(f'Input {input_index} of layer \"{layer_name}\" is '\n\n    ValueError: Input 0 of layer \"sequential_2\" is incompatible with the layer: expected shape=(None, 128, 128, 3), found shape=(32, 3, 224, 224)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.hist(train_y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        },
        "id": "iraVL9kjSHd8",
        "outputId": "ced47079-e533-4f61-a2d4-59872cbbe640"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([307., 296., 227., 214., 188., 146., 107.,  66.,  42.,   7.]),\n",
              " array([ 1.,  5.,  9., 13., 17., 21., 25., 29., 33., 37., 41.]),\n",
              " <a list of 10 Patch objects>)"
            ]
          },
          "metadata": {},
          "execution_count": 64
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Loe-nWsDVFF7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}