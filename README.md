# ğŸ”ë”¥ ëŸ¬ë‹ í”„ë¡œì íŠ¸ : ìƒìœ¡ ê¸°ê°„ ì˜ˆì¸¡
## Introduction
- í•œ ìŒì˜ ì´ë¯¸ì§€ë¥¼ ì…ë ¥ë°›ì•„ ì‘ë¬¼ì˜ ìƒìœ¡ ê¸°ê°„ì„ ì˜ˆì¸¡ì„ ëª©ì ìœ¼ë¡œ ì§„í–‰í•œ í”„ë¡œì íŠ¸ì…ë‹ˆë‹¤.(<a href='https://dacon.io/competitions/official/235851/overview/description' target='_blink'>ë°ì´ì½˜ ê²½ì§„ ëŒ€íšŒ</a>)
- ì´ë¯¸ì§€ë¥¼ CNNì„ í†µí•´ ë¶„ì„í•˜ê³  ìƒìœ¡ ê¸°ê°„ ì˜ˆì¸¡ì„ ì§„í–‰í•œë‹¤.
  
## Contents
- [1. í”„ë¡œì íŠ¸ ì†Œê°œ](#1-í”„ë¡œì íŠ¸-ì†Œê°œ) 
- [2. ë°ì´í„° ì „ì²˜ë¦¬](#2-ë°ì´í„°-ì „ì²˜ë¦¬)
- [3. ëª¨ë¸ë§](#3-ëª¨ë¸ë§)
  - [Lenet](#lenet)
  - [Mobilenet_v2](#mobilenet_v2)
  - [Resnext50_32x4d](#resnext50_32x4d)
- [4. ìµœì¢… ê²°ê³¼](#4-ìµœì¢…-ê²°ê³¼)
- [5. í•œê³„ ë° ë³´ì™„ì ](#5-í•œê³„-ë°-ë³´ì™„ì )
- [6. ì°¸ê³  ìë£Œ](#6-ì°¸ê³ -ìë£Œ)
- [7. êµ¬ì„± ì¸ì›](#7-êµ¬ì„±-ì¸ì›)

## 1. í”„ë¡œì íŠ¸ ì†Œê°œ
### ë°°ê²½
- ìŠ¤ë§ˆíŠ¸íŒœ, IT ê¸°ìˆ ì„ ë™ì›í•˜ì—¬ ë”ìš± íš¨ìœ¨ì ì¸ ì‘ë¬¼ ì¬ë°°ì˜ ê°€ëŠ¥ì„±
- ì‘ë¬¼ì˜ íš¨ìœ¨ì ì¸ ìƒìœ¡ì„ ìœ„í•œ ê°€ì¥ ìµœì ì˜ í™˜ê²½ ë„ì¶œì˜ ì¼í™˜ìœ¼ë¡œ ì‹ë¬¼ì˜ ì´ë¯¸ì§€ë¥¼ ì´ìš©í•´ ì„±ì¥ ê¸°ê°„ ì˜ˆì¸¡
- <a href='https://dacon.io/competitions/official/235851/overview/description' target='_blink'>ë°ì´ì½˜ ê²½ì§„ ëŒ€íšŒ</a>

### í”„ë¡œì íŠ¸ ê°œìš”
- êµ¬ì„±ì¸ì› : ê¹€ë‚¨ê·œ, ë°•ì´ì •, ìœ í˜„ì¤€
- ìˆ˜í–‰ê¸°ê°„ : 2021ë…„ 12ì›” 20ì¼ ~ 2021ë…„ 12ì›” 30ì¼
- ëª©í‘œ : í•œìŒì˜ ì´ë¯¸ì§€ë¥¼ í†µí•œ ìƒìœ¡ ê¸°ê°„ ì˜ˆì¸¡
- ë°ì´í„° : ì ìƒì¶”, ì²­ê²½ì±„ ì´ë¯¸ì§€
  - í•™ìŠµ : 753ê°œ(ì²­ê²½ì±„ 353ê°œ, ì ìƒì¶” 400ê°œ)
  - í…ŒìŠ¤íŠ¸ : 307ê°œ(ì²­ê²½ì±„ 139ê°œ, ì ìƒì¶” 168ê°œ)
  - í‰ê°€ì§€í‘œ : RMSE(Root Mean Square Error)

### ê°œë°œ í™˜ê²½
- ì‹œìŠ¤í…œ : Colab
- ì–¸ì–´ : Python
- ë¼ì´ë¸ŒëŸ¬ë¦¬ : **Pandas**, **Numpy**, **PIL**, **Torch**, **Torchvision**
- ì•Œê³ ë¦¬ì¦˜ : CNN(LeNet, Mobilenet_v2, Resnext50_32x4d)

## 2. ë°ì´í„° ì „ì²˜ë¦¬
#### â–ªì´ë¯¸ì§€ Resize
- ì›ë³¸ ì‚¬ì´ì¦ˆ : (3280, 2464)
  - ì‹œìŠ¤í…œ ì‚¬ì–‘ì˜ í•œê³„ë¡œ Colab í™œìš©
  - GPU ë©”ëª¨ë¦¬ ì´ˆê³¼ ë˜ëŠ” Colab ì‚¬ìš© ì‹œê°„ ì´ˆê³¼ ë°œìƒ
  - ì´ë¯¸ì§€ ì‚¬ì´ì¦ˆë¥¼ ë¯¸ë¦¬ ì¡°ì •í•˜ì—¬ í•´ê²°
- ì‚¬ìš© ì‚¬ì´ì¦ˆ : (224, 224)
  - ì´ë¯¸ì§€ë„·ì„ í™œìš©í•œ ì‚¬ì „ í•™ìŠµ ëª¨ë¸(Mobilenet_v2, Resnext50_32xd4) ì‚¬ìš©ì„ ìœ„í•´ í•´ë‹¹ ì‚¬ì´ì¦ˆë¡œ ì¡°ì ˆ
  - PIL ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ í™œìš©í•´ ëª¨ë“  ì´ë¯¸ì§€ ì‚¬ì´ì¦ˆ ì¡°ì ˆ
  ```python
  import os
  from PIL import Image

  def data_resize(species_nm,root_path):
    os.mkdir(root_path +'/'+ species_nm + '_resize')
    # ì„œë¸Œ í´ë” ìƒì„±
    for sub_path in os.listdir(root_path +'/'+ species_nm): 
      os.mkdir(root_path +'/'+ species_nm + '_resize/' + sub_path)
      # ì´ë¯¸ì§€ resize ë° ì €ì¥
      for image_path in glob(root_path +'/'+ species_nm + '/' + sub_path + '/*'): 
        image_file_name = image_path.split('/')[-1]
        img = Image.open(image_path)
        img = img.resize((224, 224))
        img.save(root_path +'/'+ species_nm + '_resize/' + sub_path + '/' + image_file_name)
  ```

## 3. ëª¨ë¸ë§
<p align="center">
<img src = 'https://postfiles.pstatic.net/MjAyMjAzMTVfMjMz/MDAxNjQ3MzE5MzI5MjI4.CAxfbx6lZKslVNr3rxU0zRiijUd_9tDXNvf_nEl7or8g._MuxaQOaULAjEVv8QOkZRfZbaCXyLMzQE92DdZz_NAog.PNG.isanghada03/SE-13d56f79-5ff1-458f-8e2c-8b422cdb29ef.png?type=w966' width="50%" height="50%"></p>  

- ëª¨ë¸ êµ¬ì¡°
  - after_net, before_net : CNNì„ í†µí•´ ì´ë¯¸ì§€ì—ì„œ ìƒìœ¡ ê¸°ê°„ì„ ë„ì¶œí•˜ëŠ” ëª¨ë¸
    - [Lenet, Mobilenet_v2, Resnext50_32xd4]ìœ¼ë¡œ êµ¬ì„±
  - CompareNet : ê° ì´ë¯¸ì§€ì—ì„œ ë„ì¶œí•œ ê²°ê³¼ë¡œ ë‘ ì´ë¯¸ì§€ ê°„ì˜ ìƒìœ¡ ê¸°ê°„ì„ ë„ì¶œí•˜ëŠ” ëª¨ë¸

### Lenet
<p align="center"><img src='https://postfiles.pstatic.net/MjAyMjAzMTVfMTM1/MDAxNjQ3MzE3NzA0ODc2.FMveD6zMA6VkEA-KodxsB6IMcIvYn2DPesq57NIKNqcg.YFUxzbJwiSPww9Gyf6EzP5Xkrc42nyS9HNbIH8iXuQkg.PNG.isanghada03/image.png?type=w966'></p>

- ê°€ì¥ ê¸°ë³¸ì ì¸ CNN(Convolutional Neural Network)ìœ¼ë¡œ Layer ì…ë ¥ê°’ê³¼ ì¶œë ¥ê°’ì„ ì´ë¯¸ì§€ í¬ê¸°ì— ë§ê²Œ ìˆ˜ì •
- ê°„ë‹¨í•œ ëª¨ë¸ë¡œ ë™ì‘ ê³¼ì •ì„ ì‚´í´ë³´ê¸° ìœ„í•´ ì§„í–‰

```python
import torch
from torch import nn
class LeNet(nn.Module):

  def __init__(self):
    super(LeNet, self).__init__()
    self.feature_extractor1 = nn.Sequential( 
      nn.Conv2d(3, 6, kernel_size=5, padding=2), 
      nn.ReLU(),
      nn.AvgPool2d(kernel_size=2, stride=2))
    self.feature_extractor2 = nn.Sequential(
      nn.Conv2d(6, 16, kernel_size=5), 
      nn.ReLU(),
      nn.AvgPool2d(kernel_size=2, stride=2))
    
    self.feature_extractor3 = nn.Sequential(
      nn.Flatten(),
    )
    self.feature_extractor4 = nn.Sequential(
      nn.Linear(16*54*54, 120), 
      nn.ReLU(),  
    )
    self.feature_extractor5 = nn.Sequential(
      nn.Linear(120, 84), 
      nn.ReLU(),
    )
    self.feature_extractor6 = nn.Sequential(
      nn.Linear(84, 10)
    )  

    self.output = nn.Sequential(
      nn.Linear(10, 1),
      )


  def forward(self, x):
    x = self.feature_extractor1(x)
    print("x1",x.shape)
    x = self.feature_extractor2(x)
    print("x2",x.shape)
    x = self.feature_extractor3(x)
    print("x3",x.shape)
    x = self.feature_extractor4(x)
    print("x4",x.shape)
    x = self.feature_extractor5(x)
    print("x5",x.shape)
    x = self.feature_extractor6(x)
    print("x6",x.shape)
    logits = self.output(x)
    print("logits", logits.shape)
    return logits

class CompareNet(nn.Module):

    def __init__(self):
        super(CompareNet, self).__init__()
        self.before_net = LeNet()
        self.after_net = LeNet()

    def forward(self, before_input, after_input):
        before = self.before_net(before_input)
        after = self.after_net(after_input)
        delta = before - after
        return delta
```  
### Mobilenet_v2
- ì‚¬ì „ í•™ìŠµ ëª¨ë¸ì„ ì‚¬ìš©í•´ êµ¬í˜„í•œ ëª¨ë¸ì„ ì„±ëŠ¥ì„ ë†’ì´ê³ ì ì‹œë„
- ê°€ë²¼ìš°ë©´ì„œ ì„±ëŠ¥ì´ ì¢‹ë‹¤ê³  ì•Œë ¤ì§„ Mobilenet_v2 ì‚¬ìš©
- EPOCHS ë³€ê²½, Image Augmentation ë“± ë‹¤ì–‘í•œ ë°©ë²•ì„ í†µí•´ ì„±ëŠ¥ í–¥ìƒ ì‹œë„
```python
import torch
from torch import nn
from torchvision.models import mobilenet_v2

class CompareCNN(nn.Module):
  def __init__(self):
    super(CompareCNN, self).__init__()
    self.mobile_net = mobilenet_v2(pretrained=True)
    self.fc_layer = nn.Linear(1000, 1)

  def forward(self, input):
    x = self.mobile_net(input)
    output = self.fc_layer(x)
    return output

class CompareNet(nn.Module):
  def __init__(self):
    super(CompareNet, self).__init__()
    self.before_net = CompareCNN()
    self.after_net = CompareCNN()

  def forward(self, before_input, after_input):
    before = self.before_net(before_input)
    after = self.after_net(after_input)
    delta = before - after
    return delta
```

### Resnext50_32x4d
- Mobilenet_v2ë³´ë‹¤ ë³µì¡í•˜ê³  ì„±ëŠ¥ì´ ì¢‹ì€ ëª¨ë¸ë¡œ ë³€ê²½í•˜ì—¬ ë¹„êµ ì§„í–‰
```python
import torch
from torch import nn
from torchvision.models import resnext50_32x4d

class CompareCNN(nn.Module):
  def __init__(self):
    super(CompareCNN, self).__init__()
    self.resnext50 = resnext50_32x4d(pretrained=True)
    self.fc_layer = nn.Linear(1000, 1)

  def forward(self, input):
    x = self.resnext50(input)
    output = self.fc_layer(x)
    return output

class CompareNet(nn.Module):
  def __init__(self):
    super(CompareNet, self).__init__()
    self.before_net = CompareCNN()
    self.after_net = CompareCNN()

  def forward(self, before_input, after_input):
    before = self.before_net(before_input)
    after = self.after_net(after_input)
    delta = before - after
    return delta
```

## 4. ìµœì¢… ê²°ê³¼
- ë°ì´ì½˜ ì œì¶œ ê²°ê³¼
  - public : ì „ì²´ í…ŒìŠ¤íŠ¸ ë°ì´í„° ì¤‘ 25%
  - private : ì „ì²´ í…ŒìŠ¤íŠ¸ ë°ì´í„° ì¤‘ 75%

<p align='center'><img src='https://postfiles.pstatic.net/MjAyMjAzMTVfMjQg/MDAxNjQ3MzIyMjk0OTI1.bWLSCrZi-tHPAOomuuvA1MsO4vlG3x6bWdG-IOzm-L0g.WWasJJvFlqFtzPA4ZQg_Sh1GoH5HHxdPzCTf9FAM56Ig.PNG.isanghada03/%EA%B7%B8%EB%A6%BC2.png?type=w966' width="90%" height="90%"></p>

- Feature Map
  - CNNì´ ì´ë¯¸ì§€ë¥¼ ë¶„ì„í•˜ëŠ” ë°©ì‹ì„ ì‚´í´ë³´ê³ ì ì§„í–‰
  - Lenetê³¼ Mobilenet_v2ë¡œ ì§„í–‰
  - [Lenet]  
  <img src='https://postfiles.pstatic.net/MjAyMjAzMTVfODUg/MDAxNjQ3MzIzMzM2Nzkw.cYt21LFNY90aL2X_3IOKpnDAygkuPJdRm-R3hxo21Cgg.Cq25sAMBdFiaiEXJjxtNwsC92WCXsySdQzyFcRp_E4Qg.PNG.isanghada03/%EA%B7%B8%EB%A6%BC3.png?type=w966' width='70%' height='70%'>
  
  - [Mobilenet_v2]  
  <img src='https://postfiles.pstatic.net/MjAyMjAzMTVfMjEy/MDAxNjQ3MzIzMzM2NjMy.UxrVQfGGRdTg7H4hGVSVBEIcN7M5DsuVbTtzn6cQcxYg.BoUPIuaN7mXmfaKXi-71xU3qZN9R2ZoTTpkXcgCtRbQg.PNG.isanghada03/%EA%B7%B8%EB%A6%BC4.png?type=w966' width='70%' height='70%'>  
  
  - **ì£¼ë¡œ ìì´ ê°•ì¡°ë˜ëŠ” ê²ƒ í™•ì¸**

## 5. í•œê³„ ë° ë³´ì™„ì 
#### ğŸ› ì‹œìŠ¤í…œ ì‚¬ì–‘ ë¶€ì¡±
- ì‚¬ìš© ë°ì´í„°ê°€ ì´ë¯¸ì§€ì´ê³  ì‚¬ì „ í•™ìŠµ ëª¨ë¸ì˜ Layerê°€ ë†’ì€ ì‹œìŠ¤í…œ ì‚¬ì–‘ì´ í•„ìš”í–ˆë‹¤.
- Colabì„ í†µí•´ ì§„í–‰í•  ìˆ˜ëŠ” ìˆì—ˆì§€ë§Œ, ì£¼ë¡œ GPU ë©”ëª¨ë¦¬ ì´ìŠˆê°€ ë°œìƒí•˜ì—¬ ì§„í–‰ì´ ë§‰íŒ ê²½ìš°ê°€ ìˆì—ˆë‹¤.
  - ì‚¬ì–‘ ë¶€ì¡±ê³¼ í•™ìŠµ ì‹œê°„ì´ ì˜¤ë˜ ê±¸ë ¤ ì£¼ë¡œ epochì„ ë³€ê²½í•˜ë©° ë¹„êµí•˜ì˜€ë‹¤.
- ì‚¬ì–‘ì´ë‚˜ í•™ìŠµ ì‹œê°„ ë¬¸ì œê°€ í•´ê²°ì´ ëœë‹¤ë©´ ìµœì ì˜ ì¡°ê±´ì„ íƒìƒ‰í•˜ê³  ì—¬ëŸ¬ ëª¨ë¸ë“¤ì„ ì•™ìƒë¸”í•˜ë©´ ì¡°ê¸ˆ ë” ì™„ì„±ë„ ë†’ì€ ëª¨ë¸ì´ ë  ìˆ˜ ìˆì„ ê²ƒì´ë¼ ìƒê°í•œë‹¤.

## 6. ì°¸ê³  ìë£Œ
- ë°ì´ì½˜ ì½”ë“œ : https://dacon.io/competitions/official/235851/codeshare
- mobilenet_v2 : https://pytorch.org/vision/main/generated/torchvision.models.mobilenet_v2.html
- resnext50_32x4d : https://pytorch.org/vision/main/generated/torchvision.models.resnext50_32x4d.html

## 7. êµ¬ì„± ì¸ì›
- ê¹€ë‚¨ê·œ (<a href = 'https://github.com/Isanghada' href='_blank'>github</a>)
- ë°•ì´ì • (<a href = 'https://github.com/happyfranc' href='_blank'>github</a>)
- ìœ í˜„ì¤€ (<a href = 'https://github.com/hyunjuyo' href='_blank'>github</a>)
